from dotenv import load_dotenv
load_dotenv()

from langchain.agents import create_agent
from langchain_core.tools import tool
from langgraph.checkpoint.memory import InMemorySaver

# Tools simples
@tool
def somar(a: int, b: int) -> int:
    """Soma dois nÃºmeros"""
    return a + b

@tool
def multiplicar(a: int, b: int) -> int:
    """Multiplica dois nÃºmeros"""
    return a * b

@tool
def clima(cidade: str) -> str:
    """Consulta o clima de uma cidade"""
    return f"O clima em {cidade} estÃ¡ 28Â°C, ensolarado."

# Checkpointer em memÃ³ria
checkpointer = InMemorySaver()

# Cria o agente com memÃ³ria
agent = create_agent(
    model="anthropic:claude-haiku-4-5-20251001",
    tools=[somar, multiplicar, clima],
    system_prompt="VocÃª Ã© um assistente Ãºtil que responde em portuguÃªs.",
    checkpointer=checkpointer
)

print("Chat com MemÃ³ria (digite 'sair' pra encerrar)\n")

config = {"configurable": {"thread_id": "conversa-1"}}

while True:
    pergunta = input("VocÃª: ")
    if pergunta.lower() == "sair":
        break

    # Ver o que tÃ¡ na memÃ³ria ANTES de responder
    estado = agent.get_state(config)
    print(f"\n  ğŸ“ Mensagens na memÃ³ria: {len(estado.values.get('messages', []))}")
    for m in estado.values.get("messages", []):
        print(f"     [{m.__class__.__name__}] {m.content[:80] if m.content else '[tool call]'}")
    print()

    resultado = agent.invoke(
        {"messages": [{"role": "user", "content": pergunta}]},
        config=config
    )

    for msg in resultado["messages"]:
        tipo = msg.__class__.__name__
        if tipo == "AIMessage" and msg.tool_calls:
            for tc in msg.tool_calls:
                print(f"  ğŸ”§ Tool chamada: {tc['name']}({tc['args']})")
        elif tipo == "ToolMessage":
            print(f"  ğŸ“¦ Resultado: {msg.content}")
        elif tipo == "AIMessage" and msg.content:
            print(f"Claude: {msg.content}\n")